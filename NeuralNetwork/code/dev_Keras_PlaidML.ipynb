{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the plaidml backend\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"metal_amd_radeon_pro_580x.0\"\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.2597 - acc: 0.9207 - val_loss: 0.0584 - val_acc: 0.9814\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0853 - acc: 0.9747 - val_loss: 0.0382 - val_acc: 0.9878\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0635 - acc: 0.9810 - val_loss: 0.0374 - val_acc: 0.9873\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0527 - acc: 0.9844 - val_loss: 0.0313 - val_acc: 0.9897\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0473 - acc: 0.9863 - val_loss: 0.0296 - val_acc: 0.9900\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0401 - acc: 0.9874 - val_loss: 0.0288 - val_acc: 0.9909\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0364 - acc: 0.9888 - val_loss: 0.0270 - val_acc: 0.9915\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0342 - acc: 0.9895 - val_loss: 0.0288 - val_acc: 0.9905\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0300 - acc: 0.9910 - val_loss: 0.0265 - val_acc: 0.9916\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0289 - acc: 0.9911 - val_loss: 0.0314 - val_acc: 0.9906\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0266 - acc: 0.9919 - val_loss: 0.0277 - val_acc: 0.9915\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0258 - acc: 0.9922 - val_loss: 0.0266 - val_acc: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe39951ce50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.026592041170597075\n",
      "Test accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"/Users/david/TFM_DATA/spec\"\n",
    "data_files = os.listdir(PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH triplets\n",
    "PATH_TRIPLETS = os.path.join(\"..\",\"triplets\", \"triplets.csv\")\n",
    "df = pd.read_csv(PATH_TRIPLETS, delimiter= \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>tr1</th>\n",
       "      <th>win1</th>\n",
       "      <th>ini1</th>\n",
       "      <th>fin1</th>\n",
       "      <th>tr2</th>\n",
       "      <th>win2</th>\n",
       "      <th>ini2</th>\n",
       "      <th>fin2</th>\n",
       "      <th>tr3</th>\n",
       "      <th>win3</th>\n",
       "      <th>ini3</th>\n",
       "      <th>fin3</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG</td>\n",
       "      <td>10</td>\n",
       "      <td>192</td>\n",
       "      <td>222</td>\n",
       "      <td>42yFmT6lc2kOBqooibIX08</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>6MAyp12bbJz8zUUSPa6Ddg</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG__10__192__222.jpg;42yFm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>42yFmT6lc2kOBqooibIX08</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>6MAyp12bbJz8zUUSPa6Ddg</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG__2__40__70.jpg;42yFmT6l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG</td>\n",
       "      <td>9</td>\n",
       "      <td>180</td>\n",
       "      <td>210</td>\n",
       "      <td>42yFmT6lc2kOBqooibIX08</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>6MAyp12bbJz8zUUSPa6Ddg</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG__9__180__210.jpg;42yFmT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>42yFmT6lc2kOBqooibIX08</td>\n",
       "      <td>7</td>\n",
       "      <td>140</td>\n",
       "      <td>170</td>\n",
       "      <td>6MAyp12bbJz8zUUSPa6Ddg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG__3__60__90.jpg;42yFmT6l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>42yFmT6lc2kOBqooibIX08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>6MAyp12bbJz8zUUSPa6Ddg</td>\n",
       "      <td>7</td>\n",
       "      <td>140</td>\n",
       "      <td>170</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG__4__80__110.jpg;42yFmT6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870795</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>42yFmT6lc2kOBqooibIX08</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>6MAyp12bbJz8zUUSPa6Ddg</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG__6__120__150.jpg;42yFmT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870796</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>42yFmT6lc2kOBqooibIX08</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>6MAyp12bbJz8zUUSPa6Ddg</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>130</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG__1__20__50.jpg;42yFmT6l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870797</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG</td>\n",
       "      <td>8</td>\n",
       "      <td>160</td>\n",
       "      <td>190</td>\n",
       "      <td>42yFmT6lc2kOBqooibIX08</td>\n",
       "      <td>7</td>\n",
       "      <td>140</td>\n",
       "      <td>170</td>\n",
       "      <td>6MAyp12bbJz8zUUSPa6Ddg</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG__8__160__190.jpg;42yFmT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870798</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>42yFmT6lc2kOBqooibIX08</td>\n",
       "      <td>7</td>\n",
       "      <td>140</td>\n",
       "      <td>170</td>\n",
       "      <td>6MAyp12bbJz8zUUSPa6Ddg</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG__0__0__30.jpg;42yFmT6lc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870799</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "      <td>42yFmT6lc2kOBqooibIX08</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>6MAyp12bbJz8zUUSPa6Ddg</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>3mUonXr6ECjJs2XPDYxWhG__2__40__70.jpg;42yFmT6l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13870800 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              a1                     tr1  win1  ini1  fin1  \\\n",
       "0         0InCPtI0kadS7s3cZrcbbY  3mUonXr6ECjJs2XPDYxWhG    10   192   222   \n",
       "1         0InCPtI0kadS7s3cZrcbbY  3mUonXr6ECjJs2XPDYxWhG     2    40    70   \n",
       "2         0InCPtI0kadS7s3cZrcbbY  3mUonXr6ECjJs2XPDYxWhG     9   180   210   \n",
       "3         0InCPtI0kadS7s3cZrcbbY  3mUonXr6ECjJs2XPDYxWhG     3    60    90   \n",
       "4         0InCPtI0kadS7s3cZrcbbY  3mUonXr6ECjJs2XPDYxWhG     4    80   110   \n",
       "...                          ...                     ...   ...   ...   ...   \n",
       "13870795  0InCPtI0kadS7s3cZrcbbY  3mUonXr6ECjJs2XPDYxWhG     6   120   150   \n",
       "13870796  0InCPtI0kadS7s3cZrcbbY  3mUonXr6ECjJs2XPDYxWhG     1    20    50   \n",
       "13870797  0InCPtI0kadS7s3cZrcbbY  3mUonXr6ECjJs2XPDYxWhG     8   160   190   \n",
       "13870798  0InCPtI0kadS7s3cZrcbbY  3mUonXr6ECjJs2XPDYxWhG     0     0    30   \n",
       "13870799  0InCPtI0kadS7s3cZrcbbY  3mUonXr6ECjJs2XPDYxWhG     2    40    70   \n",
       "\n",
       "                             tr2  win2  ini2  fin2                     tr3  \\\n",
       "0         42yFmT6lc2kOBqooibIX08     5   100   130  6MAyp12bbJz8zUUSPa6Ddg   \n",
       "1         42yFmT6lc2kOBqooibIX08     5   100   130  6MAyp12bbJz8zUUSPa6Ddg   \n",
       "2         42yFmT6lc2kOBqooibIX08     2    40    70  6MAyp12bbJz8zUUSPa6Ddg   \n",
       "3         42yFmT6lc2kOBqooibIX08     7   140   170  6MAyp12bbJz8zUUSPa6Ddg   \n",
       "4         42yFmT6lc2kOBqooibIX08     0     0    30  6MAyp12bbJz8zUUSPa6Ddg   \n",
       "...                          ...   ...   ...   ...                     ...   \n",
       "13870795  42yFmT6lc2kOBqooibIX08     6   120   150  6MAyp12bbJz8zUUSPa6Ddg   \n",
       "13870796  42yFmT6lc2kOBqooibIX08     5   100   130  6MAyp12bbJz8zUUSPa6Ddg   \n",
       "13870797  42yFmT6lc2kOBqooibIX08     7   140   170  6MAyp12bbJz8zUUSPa6Ddg   \n",
       "13870798  42yFmT6lc2kOBqooibIX08     7   140   170  6MAyp12bbJz8zUUSPa6Ddg   \n",
       "13870799  42yFmT6lc2kOBqooibIX08     3    60    90  6MAyp12bbJz8zUUSPa6Ddg   \n",
       "\n",
       "          win3  ini3  fin3                                             output  \n",
       "0            5   100   130  3mUonXr6ECjJs2XPDYxWhG__10__192__222.jpg;42yFm...  \n",
       "1            4    80   110  3mUonXr6ECjJs2XPDYxWhG__2__40__70.jpg;42yFmT6l...  \n",
       "2            6   120   150  3mUonXr6ECjJs2XPDYxWhG__9__180__210.jpg;42yFmT...  \n",
       "3            0     0    30  3mUonXr6ECjJs2XPDYxWhG__3__60__90.jpg;42yFmT6l...  \n",
       "4            7   140   170  3mUonXr6ECjJs2XPDYxWhG__4__80__110.jpg;42yFmT6...  \n",
       "...        ...   ...   ...                                                ...  \n",
       "13870795     6   120   150  3mUonXr6ECjJs2XPDYxWhG__6__120__150.jpg;42yFmT...  \n",
       "13870796     5   100   130  3mUonXr6ECjJs2XPDYxWhG__1__20__50.jpg;42yFmT6l...  \n",
       "13870797     2    40    70  3mUonXr6ECjJs2XPDYxWhG__8__160__190.jpg;42yFmT...  \n",
       "13870798     1    20    50  3mUonXr6ECjJs2XPDYxWhG__0__0__30.jpg;42yFmT6lc...  \n",
       "13870799     4    80   110  3mUonXr6ECjJs2XPDYxWhG__2__40__70.jpg;42yFmT6l...  \n",
       "\n",
       "[13870800 rows x 14 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List\n",
    "triplets_input = list(df[\"output\"])\n",
    "size_triplets_input = len(triplets_input)\n",
    "\n",
    "# Sample\n",
    "triplets_input_v1 = triplets_input[:1000]\n",
    "size_triplets_input = len(triplets_input_v1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_labels = np.sort(df.a1.unique())\n",
    "df_artists = pd.DataFrame(data = artists_labels, columns = [\"artist\"]).reset_index()\n",
    "df_artists.columns = [\"id\",\"artist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.to_categorical(df_artists.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '00XhexlJEXQstHimpZN910'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f5a104ec27dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martists_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/Spotify-xJiBt4R8/lib/python3.7/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mis\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '00XhexlJEXQstHimpZN910'"
     ]
    }
   ],
   "source": [
    "keras.utils.to_categorical(artists_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, \\\n",
    "    BatchNormalization, concatenate, AveragePooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(conv_x, filters):\n",
    "    conv_x = BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    conv_x = Conv2D(filters, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False)(conv_x)\n",
    "    conv_x = Dropout(0.2)(conv_x)\n",
    "\n",
    "    return conv_x\n",
    "\n",
    "\n",
    "def dense_block(block_x, filters, growth_rate, layers_in_block):\n",
    "    for i in range(layers_in_block):\n",
    "        each_layer = conv_layer(block_x, growth_rate)\n",
    "        block_x = concatenate([block_x, each_layer], axis=-1)\n",
    "        filters += growth_rate\n",
    "\n",
    "    return block_x, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(trans_x, tran_filters):\n",
    "    trans_x = BatchNormalization()(trans_x)\n",
    "    trans_x = Activation('relu')(trans_x)\n",
    "    trans_x = Conv2D(tran_filters, (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False)(trans_x)\n",
    "    trans_x = AveragePooling2D((2, 2), strides=(2, 2))(trans_x)\n",
    "\n",
    "    return trans_x, tran_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_net(filters, growth_rate, classes, dense_block_size, layers_in_block):\n",
    "    input_img = Input(shape=(32, 32, 3))\n",
    "    x = Conv2D(24, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False)(input_img)\n",
    "\n",
    "    dense_x = BatchNormalization()(x)\n",
    "    dense_x = Activation('relu')(x)\n",
    "\n",
    "    dense_x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(dense_x)\n",
    "    for block in range(dense_block_size - 1):\n",
    "        dense_x, filters = dense_block(dense_x, filters, growth_rate, layers_in_block)\n",
    "        dense_x, filters = transition_block(dense_x, filters)\n",
    "\n",
    "    dense_x, filters = dense_block(dense_x, filters, growth_rate, layers_in_block)\n",
    "    dense_x = BatchNormalization()(dense_x)\n",
    "    dense_x = Activation('relu')(dense_x)\n",
    "    dense_x = GlobalAveragePooling2D()(dense_x)\n",
    "\n",
    "    output = Dense(classes, activation='softmax')(dense_x)\n",
    "\n",
    "    return Model(input_img, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "Cat_test_y = np_utils.to_categorical(y_test)\n",
    "y_train=np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 24)   648         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 24)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 24)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 24)   96          max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 16, 16, 24)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 12)   2592        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 12)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 36)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 36)   144         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 16, 36)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 12)   3888        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 12)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 48)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 16, 48)   192         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 48)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 12)   5184        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 12)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 60)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 60)   240         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 60)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 12)   6480        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 12)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 72)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 72)   288         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 72)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 72)   5184        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 72)     0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8, 8, 72)     288         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 72)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 8, 12)     7776        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 8, 8, 12)     0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 8, 8, 84)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 84)     336         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 84)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 8, 12)     9072        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 8, 8, 12)     0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 8, 8, 96)     0           concatenate_5[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 96)     384         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 96)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 12)     10368       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8, 8, 12)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 8, 8, 108)    0           concatenate_6[0][0]              \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 8, 108)    432         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 108)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 12)     11664       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 8, 8, 12)     0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 8, 8, 120)    0           concatenate_7[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 8, 120)    480         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 120)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 120)    14400       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 120)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 4, 120)    480         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 120)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 12)     12960       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 4, 4, 12)     0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 4, 4, 132)    0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 4, 132)    528         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 132)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 12)     14256       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 4, 4, 12)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 4, 4, 144)    0           concatenate_9[0][0]              \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 4, 144)    576         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 144)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 12)     15552       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 4, 4, 12)     0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 4, 4, 156)    0           concatenate_10[0][0]             \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 4, 156)    624         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 156)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 4, 12)     16848       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 4, 4, 12)     0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 4, 4, 168)    0           concatenate_11[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 4, 4, 168)    672         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 168)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 168)          0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            338         global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 142,970\n",
      "Trainable params: 140,090\n",
      "Non-trainable params: 2,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_block_size = 3\n",
    "layers_in_block = 4\n",
    "\n",
    "growth_rate = 12\n",
    "classes = 2\n",
    "model = dense_net(growth_rate * 2, growth_rate, classes, dense_block_size, layers_in_block)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-47d2c16f1464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCat_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train,y_train, epochs=epochs, batch_size=batch_size, shuffle=True,validation_data=(X_test, Cat_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "# plot the training loss and accuracy\n",
    "import sys\n",
    "import matplotlib\n",
    "print(\"Generating plots...\")\n",
    "sys.stdout.flush()\n",
    "matplotlib.use(\"Agg\")\n",
    "matplotlib.pyplot.style.use(\"ggplot\")\n",
    "matplotlib.pyplot.figure()\n",
    "N = epochs \n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "matplotlib.pyplot.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "matplotlib.pyplot.title(\"Cactus Image Classification\")\n",
    "matplotlib.pyplot.xlabel(\"Epoch #\")\n",
    "matplotlib.pyplot.ylabel(\"Loss/Accuracy\")\n",
    "matplotlib.pyplot.legend(loc=\"lower left\")\n",
    "matplotlib.pyplot.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy for each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "label_pred = model.predict(X_test)\n",
    "\n",
    "pred = []\n",
    "for i in range(len(label_pred)):\n",
    "    pred.append(np.argmax(label_pred[i]))\n",
    "\n",
    "Y_test = np.argmax(Cat_test_y, axis=1) # Convert one-hot to index\n",
    "\n",
    "print(metrics.classification_report(Y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "label_pred = model.predict(X_test)\n",
    "\n",
    "pred = []\n",
    "for i in range(len(label_pred)):\n",
    "    pred.append(np.argmax(label_pred[i]))\n",
    "\n",
    "Y_test = np.argmax(Cat_test_y, axis=1) # Convert one-hot to index\n",
    "\n",
    "print(metrics.accuracy_score(Y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
