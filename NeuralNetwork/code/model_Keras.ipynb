{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the plaidml backend\n",
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, \\\n",
    "    BatchNormalization, concatenate, AveragePooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "from py2neo import Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"/Users/david/TFM_DATA/spec\"\n",
    "data_files = os.listdir(PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH triplets\n",
    "PATH_TRIPLETS = os.path.join(\"..\",\"triplets\", \"triplets.csv\")\n",
    "df = pd.read_csv(PATH_TRIPLETS, delimiter= \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List\n",
    "triplets_input = list(df[\"output\"])\n",
    "size_triplets_input = len(triplets_input)\n",
    "\n",
    "# Sample\n",
    "triplets_input_v1 = triplets_input[:1000]\n",
    "size_triplets_input = len(triplets_input_v1)\n",
    "\n",
    "# Artists\n",
    "artists_labels = np.sort(df.a1.unique())\n",
    "df_artists = pd.DataFrame(data = artists_labels, columns = [\"artist\"]).reset_index()\n",
    "df_artists.columns = [\"id\",\"artist\"]\n",
    "\n",
    "# DF Artists with artists as index\n",
    "df_artists_index = df_artists.set_index(\"artist\")\n",
    "num_artists = df_artists.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catalan music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(bolt = True, host = \"localhost\", name = \"Spotify\", user = \"neo4j\", password = \"qrks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        MATCH (g:Genre)-[:GEN_ART]->(a:Artist)\n",
    "        MATCH (a:Artist)-[:REL_ART]->(a2:Artist)\n",
    "        WHERE toLower(g.genre_id) =~ '.*catala.*'\n",
    "        RETURN a.artist_id, a2.artist_id\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = graph.run(query)\n",
    "dfneo = pd.DataFrame.from_records(cursor, columns=cursor.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_art_cat = set()\n",
    "for ii, row in dfneo.iterrows():\n",
    "    set_art_cat.add(row[\"a.artist_id\"])\n",
    "    set_art_cat.add(row[\"a2.artist_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: select couple of artists\n",
    "sel_art = list(set_art_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists_cat = df_artists[df_artists.artist.isin(set_art_cat)][\"artist\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists_cat[\"id\"] = df_artists_cat.index\n",
    "df_artists_cat.drop('index', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists_gen = df_artists_cat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_mat = keras.utils.to_categorical(df_artists_index.id)\n",
    "labels_mat = keras.utils.to_categorical(df_artists_gen.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dict()\n",
    "for i, row in df_artists_gen.iterrows():\n",
    "    labels[row.artist] = labels_mat[row.id,].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_artists = len(labels.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = df[df.a1.isin(set_art_cat)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dataframe Classiset_art_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_gen[[\"a1\",\"tr1\",\"win1\",\"ini1\",\"fin1\"]].copy()\n",
    "df2 = df_gen[[\"a1\",\"tr2\",\"win2\",\"ini2\",\"fin2\"]].copy()\n",
    "\n",
    "#Â Column names\n",
    "colnames = [\"art\",\"tr\",\"win\",\"ini\",\"fin\"]\n",
    "df1.columns = colnames\n",
    "df2.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1, df2])\n",
    "df_concat.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat[\"tr\"] = df_concat.tr + \"__\" + df_concat.win.astype(str) +  \\\n",
    "    \"__\" + df_concat.ini.astype(str) + \"__\" + df_concat.fin.astype(str) + \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>art</th>\n",
       "      <th>tr</th>\n",
       "      <th>win</th>\n",
       "      <th>ini</th>\n",
       "      <th>fin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13869032</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>7hiceWoDGGP4RadNyGxRdm__2__40__70.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869034</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>7hiceWoDGGP4RadNyGxRdm__4__80__110.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869041</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>7hiceWoDGGP4RadNyGxRdm__7__140__170.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>140</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869051</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>7hiceWoDGGP4RadNyGxRdm__6__120__150.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869061</th>\n",
       "      <td>0InCPtI0kadS7s3cZrcbbY</td>\n",
       "      <td>7hiceWoDGGP4RadNyGxRdm__9__180__210.jpg</td>\n",
       "      <td>9</td>\n",
       "      <td>180</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             art                                       tr  \\\n",
       "13869032  0InCPtI0kadS7s3cZrcbbY    7hiceWoDGGP4RadNyGxRdm__2__40__70.jpg   \n",
       "13869034  0InCPtI0kadS7s3cZrcbbY   7hiceWoDGGP4RadNyGxRdm__4__80__110.jpg   \n",
       "13869041  0InCPtI0kadS7s3cZrcbbY  7hiceWoDGGP4RadNyGxRdm__7__140__170.jpg   \n",
       "13869051  0InCPtI0kadS7s3cZrcbbY  7hiceWoDGGP4RadNyGxRdm__6__120__150.jpg   \n",
       "13869061  0InCPtI0kadS7s3cZrcbbY  7hiceWoDGGP4RadNyGxRdm__9__180__210.jpg   \n",
       "\n",
       "          win  ini  fin  \n",
       "13869032    2   40   70  \n",
       "13869034    4   80  110  \n",
       "13869041    7  140  170  \n",
       "13869051    6  120  150  \n",
       "13869061    9  180  210  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = df_concat.reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, df, scaling, x_col, y_col=None, batch_size=10, num_classes=None, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.indices = self.df.index.tolist()\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.x_col = x_col\n",
    "        self.y_col = y_col\n",
    "        self.dim = (int(x_col / scaling), int(y_col / scaling), 1) #one input channel\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        idx = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in idx]\n",
    "        \n",
    "        X, y = self.__get_data(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size, self.num_classes), dtype=int)\n",
    "        \n",
    "        # Get the list of image files and corresponding artists\n",
    "        df_imgs_files = self.df.iloc[batch]\n",
    "        \n",
    "        list_imgs = list(df_imgs_files[\"tr\"])\n",
    "        list_art = list(df_imgs_files[\"art\"])\n",
    "        \n",
    "        for ii in range(len(list_imgs)):\n",
    "            \n",
    "            # Read image using cv2\n",
    "            path_img = os.path.join(PATH_DATA, list_imgs[ii])\n",
    "            img = cv2.cvtColor(cv2.imread(path_img), cv2.COLOR_BGR2GRAY)\n",
    "            img = np.round(img / 255.,5)\n",
    "            img = cv2.resize(img, (self.y_col, self.x_col))\n",
    "            img = cv2.resize(img, (self.dim[1], self.dim[0]))\n",
    "            img = np.expand_dims(img, axis = 2) # add the dimension of the channel \n",
    "            \n",
    "            # Put it into X matrix\n",
    "            X[ii,] = img\n",
    "            y[ii] = labels[list_art[ii]]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col, y_col = (256, 937)\n",
    "batch_size = 5\n",
    "num_classes = df_artists.shape[0]\n",
    "shuffle = False\n",
    "scaling = 1\n",
    "\n",
    "training_generator = DataGenerator(df=df_concat, \n",
    "                                   scaling = scaling,\n",
    "                                   x_col=x_col, \n",
    "                                   y_col=y_col,\n",
    "                                   batch_size=batch_size, \n",
    "                                   num_classes=num_artists,\n",
    "                                   shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(conv_x, filters):\n",
    "    conv_x = BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    conv_x = Conv2D(filters, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False)(conv_x)\n",
    "    conv_x = Dropout(0.2)(conv_x)\n",
    "\n",
    "    return conv_x\n",
    "\n",
    "\n",
    "def dense_block(block_x, filters, growth_rate, layers_in_block):\n",
    "    for i in range(layers_in_block):\n",
    "        each_layer = conv_layer(block_x, growth_rate)\n",
    "        block_x = concatenate([block_x, each_layer], axis=-1)\n",
    "        filters += growth_rate\n",
    "\n",
    "    return block_x, filters\n",
    "\n",
    "def transition_block(trans_x, tran_filters):\n",
    "    trans_x = BatchNormalization()(trans_x)\n",
    "    trans_x = Activation('relu')(trans_x)\n",
    "    trans_x = Conv2D(tran_filters, (1, 1), kernel_initializer='he_uniform', padding='same', use_bias=False)(trans_x)\n",
    "    trans_x = AveragePooling2D((2, 2), strides=(2, 2))(trans_x)\n",
    "\n",
    "    return trans_x, tran_filters\n",
    "\n",
    "def dense_net(filters, growth_rate, classes, dense_block_size, layers_in_block, in_shape):\n",
    "    input_img = Input(shape=in_shape)\n",
    "    x = Conv2D(3, (3, 3), kernel_initializer='he_uniform', padding='same', use_bias=False)(input_img)\n",
    "\n",
    "    dense_x = BatchNormalization()(x)\n",
    "    dense_x = Activation('relu')(x)\n",
    "\n",
    "    dense_x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(dense_x)\n",
    "    for block in range(dense_block_size - 1):\n",
    "        dense_x, filters = dense_block(dense_x, filters, growth_rate, layers_in_block)\n",
    "        dense_x, filters = transition_block(dense_x, filters)\n",
    "\n",
    "    dense_x, filters = dense_block(dense_x, filters, growth_rate, layers_in_block)\n",
    "    dense_x = BatchNormalization()(dense_x)\n",
    "    dense_x = Activation('relu')(dense_x)\n",
    "    dense_x = GlobalAveragePooling2D()(dense_x)\n",
    "\n",
    "    output = Dense(classes, activation='softmax')(dense_x)\n",
    "\n",
    "    return Model(input_img, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_CNN(input_shape, num_classes):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(2, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(4, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_block_size = 4\n",
    "layers_in_block = 2\n",
    "\n",
    "in_shape = (int(x_col / scaling), int(y_col / scaling), 1)\n",
    "growth_rate = 2\n",
    "classes = num_artists\n",
    "\n",
    "#model = dense_net(growth_rate * 2, growth_rate, classes, dense_block_size, layers_in_block, in_shape)\n",
    "model = quick_CNN(input_shape=in_shape, num_classes = classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "epochs = 10\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "383/383 [==============================] - 73s 190ms/step - loss: 3.7707 - acc: 0.0512\n",
      "Epoch 2/10\n",
      "383/383 [==============================] - 66s 172ms/step - loss: 2.8787 - acc: 0.0799\n",
      "Epoch 3/10\n",
      "383/383 [==============================] - 66s 173ms/step - loss: 2.8723 - acc: 0.0799\n",
      "Epoch 4/10\n",
      "383/383 [==============================] - 71s 186ms/step - loss: 2.8675 - acc: 0.0799\n",
      "Epoch 5/10\n",
      "383/383 [==============================] - 39s 103ms/step - loss: 2.8639 - acc: 0.0799\n",
      "Epoch 6/10\n",
      "383/383 [==============================] - 29s 76ms/step - loss: 2.8608 - acc: 0.0799\n",
      "Epoch 7/10\n",
      "383/383 [==============================] - 29s 76ms/step - loss: 2.8585 - acc: 0.0799\n",
      "Epoch 8/10\n",
      "383/383 [==============================] - 29s 76ms/step - loss: 2.8565 - acc: 0.0799\n",
      "Epoch 9/10\n",
      "383/383 [==============================] - 29s 76ms/step - loss: 2.8548 - acc: 0.0799\n",
      "Epoch 10/10\n",
      "383/383 [==============================] - 29s 76ms/step - loss: 2.8535 - acc: 0.0799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb73b9afad0>"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = training_generator, \n",
    "          epochs=epochs, \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
