{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch\n",
    "import torchvision\n",
    "import torch.utils.data as utils\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Torch network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Other\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd \n",
    "import boto3\n",
    "import io\n",
    "import cv2\n",
    "from v_log import VLogger\n",
    "import tqdm\n",
    "from collections import OrderedDict\n",
    "from importlib import reload  \n",
    "\n",
    "# Load Triplets\n",
    "import s3fs\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Imported files\n",
    "# Imported files\n",
    "import densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "PATH_DATA = \"/home/ubuntu/data\"\n",
    "data_files = os.listdir(PATH_DATA)\n",
    "\n",
    "# Path Results\n",
    "PATH_RESULTS_MODEL = \"/home/ubuntu/siamese/model_results/\"\n",
    "\n",
    "# Name of experiment\n",
    "EXP_NAME = \"densenet_v1\"\n",
    "if EXP_NAME not in os.listdir(PATH_RESULTS_MODEL):\n",
    "    #Create the folder of the EXP_NAME if not exists in the model_results folder\n",
    "    os.mkdir(os.path.join(PATH_RESULTS_MODEL, EXP_NAME))\n",
    "    \n",
    "# Path LOGS\n",
    "PATH_LOGS = os.path.join(PATH_RESULTS_MODEL, \"logs\")\n",
    "if \"logs\" not in os.listdir(PATH_RESULTS_MODEL):\n",
    "    #Create the folder of the EXP_NAME if not exists in the model_results folder\n",
    "    os.mkdir(os.path.join(PATH_RESULTS_MODEL, \"logs\"))\n",
    "PATH_LOG_FILE = os.path.join(PATH_LOGS, EXP_NAME + \".log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start logging\n",
    "log = VLogger(EXP_NAME, uri_log = PATH_LOG_FILE)a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplets: read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/ubuntu/triplets/triplets.csv\", delimiter= \";\")\n",
    "\n",
    "# List\n",
    "triplets_input = list(df[\"output\"])\n",
    "size_triplets_input = len(triplets_input)\n",
    "\n",
    "# Sample\n",
    "triplets_input_v1 = triplets_input[:1000]\n",
    "size_triplets_input = len(triplets_input_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triplet Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoader(torch.utils.data.Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, triplets_input, transform):\n",
    "        self.triplets = triplets_input\n",
    "        self.transform = transform\n",
    "        \n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # Given an index of the dataframe\n",
    "        row = self.triplets[index]\n",
    "        name_img1, name_img2, name_img3, _ = row.split(\";\")\n",
    "        \n",
    "        # Paths of .jpg according to the df row that we are processing\n",
    "        path_img1 = os.path.join(PATH_DATA,name_img1)\n",
    "        path_img2 = os.path.join(PATH_DATA,name_img2)\n",
    "        path_img3 = os.path.join(PATH_DATA,name_img3)\n",
    "                \n",
    "        img1 = cv2.cvtColor(cv2.imread(path_img1), cv2.COLOR_BGR2GRAY)\n",
    "        img2 = cv2.cvtColor(cv2.imread(path_img2), cv2.COLOR_BGR2GRAY)\n",
    "        img3 = cv2.cvtColor(cv2.imread(path_img3), cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Resize to 256, 937\n",
    "        img1 = cv2.resize(img1, (937, 256))\n",
    "        img2 = cv2.resize(img2, (937, 256))\n",
    "        img3 = cv2.resize(img3, (937, 256))\n",
    "        \n",
    "        # Transform (normalize)\n",
    "        img1 = self.transform(img1)\n",
    "        img2 = self.transform(img2)\n",
    "        img3 = self.transform(img3)\n",
    "        \n",
    "        # Normalize from 0-255 to 0-1\n",
    "        img1 /= 255.\n",
    "        img2 /= 255.\n",
    "        img3 /= 255.      \n",
    "        \n",
    "        return img1, img2, img3\n",
    "    \n",
    "    # overwrite the __len__ method\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "        \n",
    "        return img1, img2, img3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(triplets_input, cuda_bool, batch_size):\n",
    "    \n",
    "    # If CUDA enabled\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if cuda_bool else {}\n",
    "    \n",
    "    # Data Loader\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        TripletLoader(triplets_input,transform = transforms.Compose([transforms.ToTensor()])),\n",
    "        batch_size = batch_size, \n",
    "        shuffle = False, \n",
    "        **kwargs)\n",
    "    \n",
    "    return train_data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hyp, device, gpu_devices):\n",
    "    \"\"\"\n",
    "    hyp: hyper parameters of the DenseNet in a dictionary\n",
    "    Keys:\n",
    "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config (list of 3 or 4 ints) - how many layers in each pooling block\n",
    "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "            (i.e. bn_size * k features in the bottleneck layer)\n",
    "        drop_rate (float) - dropout rate after each dense layer\n",
    "        num_classes (int) - number of classification classes\n",
    "        small_inputs (bool) - set to True if images are 32x32. Otherwise assumes images are larger.\n",
    "        efficient (bool) - set to True to use checkpointing. Much more memory efficient, but slower.\n",
    "        \n",
    "    gpu_devices: List of al the devices\n",
    "    device: CPU or GPU\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the class for the DenseNet\n",
    "    model = TripletNet(densenet.DenseNet, hyp)\n",
    "    \n",
    "    # Data Parallelization on GPU\n",
    "    model = nn.DataParallel(model, device_ids = gpu_devices)\n",
    "    \n",
    "    # Put to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Load weights if provided\n",
    "    # (Disabled for this case, we will train from scratch)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, DenseNetModel, hyperparamsDenseNet):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embeddingNet = DenseNetModel(**hyperparamsDenseNet)\n",
    "\n",
    "    def forward(self, i1, i2, i3):\n",
    "        E1 = self.embeddingNet(i1)\n",
    "        E2 = self.embeddingNet(i2)\n",
    "        E3 = self.embeddingNet(i3)\n",
    "        return E1, E2, E3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data_loader, model, criterion, \n",
    "          optimizer, epoch, cuda_device):\n",
    "    \n",
    "    # Tell the object model to enter into the train mode\n",
    "    model.train()\n",
    "    \n",
    "    # LOSS FUNCTION REINITIALIZE before next batch\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, img_triplet in tqdm.tqdm(enumerate(train_data_loader)):\n",
    "        \n",
    "        ### ---------------------------------------- ###\n",
    "        ### ---------------------------------------- ###\n",
    "        #               DATA LOAD\n",
    "        ### ---------------------------------------- ###\n",
    "        ### ---------------------------------------- ###\n",
    "        # Load the triplet (if batch = 10, then anchor_img size will be 10, 256, 937)\n",
    "        anchor_img, pos_img, neg_img = img_triplet\n",
    "        \n",
    "        # Write the images into GPU ito cuda_device (if it's = 'cpu' then nothing occurs)\n",
    "        anchor_img, pos_img, neg_img = anchor_img.to(cuda_device), pos_img.to(cuda_device), neg_img.to(cuda_device)\n",
    "        \n",
    "        # Convert images to Variables\n",
    "        anchor_img, pos_img, neg_img = Variable(anchor_img), Variable(pos_img), Variable(neg_img)\n",
    "        \n",
    "        ### ---------------------------------------- ###\n",
    "        ### ---------------------------------------- ###\n",
    "        #               MODEL FORWARD PROPAGATION\n",
    "        ### ---------------------------------------- ###\n",
    "        ### ---------------------------------------- ###\n",
    "        # Forward propagation\n",
    "        E1, E2, E3 = model(anchor_img, pos_img, neg_img)\n",
    "        \n",
    "        # Distance of final embeddings\n",
    "        dist_E1_E2 = F.pairwise_distance(E1, E2, 2) # same artist\n",
    "        dist_E1_E3 = F.pairwise_distance(E1, E3, 2) # different artist\n",
    "        \n",
    "        \n",
    "        ### ---------------------------------------- ###\n",
    "        ### ---------------------------------------- ###\n",
    "        #               LOSS FUNCTION\n",
    "        ### ---------------------------------------- ###\n",
    "        ### ---------------------------------------- ###\n",
    "        # Create the target for the Margin Ranking Loss\n",
    "        # in this case = -1 since the first input (dist_E1_E2) should have\n",
    "        # a LOWER value than the second (dist_E1_E3)\n",
    "        target = torch.FloatTensor(dist_E1_E2.size()).fill_(-1)\n",
    "        target = target.to(device)\n",
    "        target = Variable(target)\n",
    "        \n",
    "        # Call the loss function\n",
    "        loss = criterion(dist_E1_E2, dist_E1_E3, target)\n",
    "        total_loss += loss\n",
    "        \n",
    "        ### ---------------------------------------- ###\n",
    "        ### ---------------------------------------- ###\n",
    "        #               OPTIMIZATION\n",
    "        ### ---------------------------------------- ###\n",
    "        ### ---------------------------------------- ###\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### ---------------------------------------- ###\n",
    "        ### ---------------------------------------- ###\n",
    "        #               LOG the loss\n",
    "        ### ---------------------------------------- ###\n",
    "        ### ---------------------------------------- ###\n",
    "        # log the loss at each log_step batches (if 100, each 100 batches will monitor\n",
    "        # the loss from 0-100, from 100-200, reseting the total_loss counter to 0\n",
    "        log_step = 10 \n",
    "        if (batch_idx % log_step == 0) and (batch_idx != 0):\n",
    "            log.info('Train Epoch: {} [{}/{}] \\t Loss: {:.4f}'.format(epoch, batch_idx, size_triplets_input,\n",
    "                                                                      total_loss / log_step))\n",
    "            total_loss = 0\n",
    "        \n",
    "    return anchor_img, pos_img, neg_img "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(epoch, model):\n",
    "    model_to_save = {\"epoch\": epoch + 1,'state_dict': model.state_dict()}\n",
    "    file_name = os.path.join(PATH_RESULTS_MODEL,EXP_NAME, \"epoch_\" + str(epoch) + \".pth\")\n",
    "    torch.save(model_to_save, file_name)\n",
    "    log.info(f\"Saved model checkpoint as: {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def main():\n",
    "# Script: train.py\n",
    "\n",
    "### --------------------------------------------- ###\n",
    "### --------------------------------------------- ###\n",
    "#               OVERALL PARAMETERS\n",
    "### --------------------------------------------- ###\n",
    "### --------------------------------------------- ###\n",
    "epochs = 2\n",
    "batch_size = 5\n",
    "cuda_bool = False\n",
    "checkpoint_freq_epoch = 1\n",
    "triplets_input = triplets_input_v1 # LIST OF THE TRIPLETS separated by ;\n",
    "learning_rate = 0.001\n",
    "\n",
    "# KEY!!!! This is the KEY part, we won't set the difference of 1, since the triplets\n",
    "# are constructed using a SIMILAR artist, then, we want to somehow preserve that similarity\n",
    "# without affecting the real objective, which is to have similar embedding for the anchor and positive image\n",
    "# compared to anchor and negative one, but, maybe anchor and negative one should be closer than anchor and a \n",
    "# \"easy negative\" one.\n",
    "margin = 0.5 # margin for the Triplet Loss euclidean distance \n",
    "\n",
    "# Final EMBEDDING size\n",
    "SIZE_EMBEDDING = 64\n",
    "\n",
    "### --------------------------------------------- ###\n",
    "### --------------------------------------------- ###\n",
    "\n",
    "### --------------------------------------------- ###\n",
    "### --------------------------------------------- ###\n",
    "# CUDA\n",
    "if cuda_bool:\n",
    "    cuda_device = \"cuda\"\n",
    "else:\n",
    "    cuda_device = \"cpu\" #or \"cuda\"\n",
    "    gpu_devices = None\n",
    "### --------------------------------------------- ###\n",
    "\n",
    "\n",
    "### --------------------------------------------- ###\n",
    "### --------------------------------------------- ###\n",
    "#  NETWORK: PARAMETERS of DENSENET\n",
    "hyp = {\n",
    "    \"growth_rate\":12, \"block_config\":(6,6,6), \n",
    "    \"compression\":0.5, \"num_init_features\":4, \n",
    "    \"bn_size\":4, # 4 times the growth rate\n",
    "    \"drop_rate\":0, \"num_classes\":10, \"small_inputs\":True, \"efficient\":False,\n",
    "    \"input_channels\": 1, \"SIZE_EMBEDDING\": SIZE_EMBEDDING\n",
    "}\n",
    "### --------------------------------------------- ###\n",
    "\n",
    "\n",
    "### --------------------------------------------- ###\n",
    "### --------------------------------------------- ###\n",
    "# MODEL: Build model\n",
    "\n",
    "model = get_model(hyp, cuda_device, gpu_devices)\n",
    "### --------------------------------------------- ###\n",
    "\n",
    "\n",
    "### --------------------------------------------- ###\n",
    "### --------------------------------------------- ###\n",
    "# CRITERION and OPTIMIZER: Retrieve the list of params in that moment of the network optimizer\n",
    "params = []\n",
    "for key, value in dict(model1.named_parameters()).items():\n",
    "    if value.requires_grad:\n",
    "        params += [{'params': [value]}]\n",
    "\n",
    "\n",
    "criterion = torch.nn.MarginRankingLoss(margin=margin)\n",
    "optimizer = optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "\n",
    "### --------------------------------------------- ###\n",
    "### --------------------------------------------- ###\n",
    "#          EPOCH TRAINING LOOP\n",
    "### --------------------------------------------- ###\n",
    "### --------------------------------------------- ###\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    \n",
    "        \n",
    "    # Log\n",
    "    log.info(\"---------------------------------------------\")\n",
    "    log.info(\"---------------------------------------------\")\n",
    "    log.info(f\"----------   START EPOCH {epoch}  ----------\")\n",
    "    log.info(\"---------------------------------------------\")\n",
    "    log.info(\"---------------------------------------------\")\n",
    "\n",
    "    # Get the data loader object\n",
    "    train_data_loader = get_loader(triplets_input, cuda_bool, batch_size)\n",
    "\n",
    "    # Train the model at each batches\n",
    "    anchor_img, pos_img, neg_img  = train(train_data_loader,\n",
    "                                          model, criterion, \n",
    "                                          optimizer, epochs, \n",
    "                                          cuda_device) #TODO\n",
    "\n",
    "    # Save model at each epoch\n",
    "    save_model(epoch, model)\n",
    "    \n",
    "    # Log\n",
    "    log.info(\"---------------------------------------------\")\n",
    "    log.info(\"---------------------------------------------\")\n",
    "    log.info(f\"----------     END EPOCH {epoch}  ----------\")\n",
    "    log.info(\"---------------------------------------------\")\n",
    "    log.info(\"---------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
