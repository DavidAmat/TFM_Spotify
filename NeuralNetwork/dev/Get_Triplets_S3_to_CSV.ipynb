{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Triplets from S3 to local CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pandas as pd \n",
    "import boto3\n",
    "import io\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = \"/home/ubuntu/data\"\n",
    "data_files = os.listdir(PATH_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "session = boto3.Session()\n",
    "\n",
    "# BUcket and parquet name\n",
    "BUCKET = \"tfmdavid\"\n",
    "PARQUET_NAME = \"triplets.parquet\"\n",
    "\n",
    "# List objects\n",
    "response = s3.list_objects_v2(Bucket = BUCKET, Prefix= PARQUET_NAME)\n",
    "parquet_file_names = [item[\"Key\"] for item in response['Contents']]\n",
    "\n",
    "# Retrieve triplets, specify the s3fs object to download parquet\n",
    "path_parquet = f's3://{BUCKET}/{PARQUET_NAME}'\n",
    "s3_FileSystem = s3fs.S3FileSystem(session = session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_triplets(s3):\n",
    "    # List all the .parquet files partitioned inside the parquet folder\n",
    "    parq_part = s3.ls(path_parquet)\n",
    "    parq_part_dwn = list()\n",
    "    for pp in parq_part:\n",
    "        if pp.endswith(\"snappy.parquet\"):\n",
    "            parq_part_dwn.append(pp.split(\"/\")[-1])\n",
    "\n",
    "    for ii, pp in enumerate(parq_part_dwn):\n",
    "        if ii == 0:\n",
    "            df = pq.ParquetDataset(path_parquet + \"/\" + pp, filesystem=s3).read_pandas().to_pandas()\n",
    "        else:\n",
    "            df2 = pq.ParquetDataset(path_parquet + \"/\" + pp, filesystem=s3).read_pandas().to_pandas()\n",
    "            df = pd.concat([df, df2])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_triplets(s3_FileSystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to .csv\n",
    "df.to_csv(\"/home/ubuntu/triplets/triplets.csv\", index=False, sep = \";\", header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
